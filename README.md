
# Evaluating Multimodal Models for Inâ€‘Hospital Mortality Prediction

This repository contains the code and data needed to reproduce our NeurIPSÂ 2024 paper:  
**â€œEvaluating the Efficacy of Multimodal Models in Clinical Prediction: A Comparative Study of BERT and Multimodal Architectures.â€**

We show that a simple TFâ€‘IDF keyword filtering step on clinical notes enables a vanilla BERT model to outperform more complex multimodal fusion architectures on inâ€‘hospital mortality prediction.

---

## ğŸš€ Quickstart

1. **Clone the repo**  
   ```bash
   git clone https://github.com/yourusername/clinicalâ€‘bertâ€‘multimodal.git
   cd clinicalâ€‘bertâ€‘multimodal
````

2. **Create your environment**

   ```bash
   # using conda
   conda env create -f environment.yml
   conda activate clinicalâ€‘bert
   ```

   *or*

   ```bash
   pip install -r requirements.txt
   ```

3. **Download and prepare data**

   ```bash
   bash scripts/download_data.sh
   python notebooks/01_data_preprocessing.ipynb
   ```

4. **Run experiments**

   ```bash
   # textâ€only baseline
   python src/train.py --mode text_only --output_dir models/baseline/

   # text + keyword extraction
   python src/train.py --mode text_keyword --output_dir models/bert_filtered/

   # text + structured
   python src/train.py --mode text_struct --output_dir models/text_struct/

   # full multimodal
   python src/train.py --mode text_struct_image --output_dir models/multimodal/
   ```

5. **Evaluate and plot**

   ```bash
   python src/evaluate.py --model_dir models/bert_filtered/ --metrics results/bert_filtered_metrics.csv
   python notebooks/03_plot_results.ipynb
   ```

---

## ğŸ“¦ Contents

* `data/` â€” clinical notes CSV, lab values, image embeddings.
* `src/`Â â€” core Python modules:

  * **`dataset.py`**Â defines PyTorchÂ `Dataset` classes for each modality.
  * **`models.py`**Â implements BERT, 2â€‘modal, and 3â€‘modal fusion architectures.
  * **`train.py`**Â contains training loops with thresholdâ€calibration and classâ€‘imbalance handling.
  * **`evaluate.py`**Â computes AUC, F1, precision, recall, etc.
  * **`utils.py`**Â includes TFâ€‘IDF keyword extraction and cleaning routines.
* `notebooks/` â€” exploratory and plotting Jupyter notebooks.
* `scripts/` â€” helper shell scripts to download data and batchâ€launch experiments.
* `models/` â€” saved checkpoints for bestâ€performing runs.
* `figures/`Â â€” highâ€‘resolution PNGs for paper figures.
* `results/` â€” CSV summaries and training curves.

---

## ğŸ“‹ Dependencies

* PythonÂ â‰¥Â 3.8
* PyTorchÂ â‰¥Â 1.10
* TransformersÂ (HuggingÂ Face)
* scikit-learn, pandas, NumPy, tqdm
* matplotlib, seaborn (optional for plotting)
* jupyter (for notebooks)

*All dependencies listed in* `environment.yml` *or* `requirements.txt`.

---

## ğŸ“‚ Pretrained Models & Data

* **Text encoder:**Â HuggingÂ Face `bert-base-uncased` (or `emilyalsentzer/Bio_ClinicalBERT`).
* **Radiology embeddings:**Â precomputed 1024â€‘dim vectors from a CNN pretrained on CheXpert.
* **Datasets:**

  * **MIMICâ€‘IVâ€‘Note v2.2**Â (freeâ€‘text clinical notes)
    JohnsonÂ etÂ al.Â (2023), [https://doi.org/10.13026/1n74-ne17](https://doi.org/10.13026/1n74-ne17)
  * **MIMICâ€‘CXR v2.0.0**Â (chest xâ€‘ray embeddings)
    JohnsonÂ etÂ al.Â (2019), [https://doi.org/10.13026/C2JT1Q](https://doi.org/10.13026/C2JT1Q)

Scripts to fetch and preprocess these are in `scripts/`.

---

## ğŸ”„ Reproducibility

* We fix random seeds for NumPy and PyTorch.
* Training, validation splits are stratified on the mortality label (80/20).
* Hyperparameters (learning rate, batch size, weight decay, dropout) are logged in `src/train.py`.
* We apply dynamic threshold calibration to match the positive class prevalence.

---

## ğŸ“‘ Citation

If you use this code in your work, please cite:

> Yang, A.*, Wu, R.* & Krishnaswamy, S. (2024). Evaluating the Efficacy of Multimodal Models in Clinical Prediction: A Comparative Study of BERT and Multimodal Architectures. *NeurIPSÂ 2024*.

---

## ğŸ¤ Acknowledgments

* This work uses MIMICâ€‘IV and MIMICâ€‘CXR from PhysioNet (JohnsonÂ etÂ al.).
* We thank **SmitaÂ Krishnaswamy** (Yale) for guidance and the TensorFlow team for openâ€source tools.
* Code template inspired by HuggingÂ Face and PyTorch examples.

---

## ğŸ”’ License

This project is released under theÂ [MIT License](LICENSE).


